# üìà DATA OUTPUT - Target Variables

## Project Title
**Predicting the Volatility and Risk Level of Stock Prices of FDI Enterprises Listed in Vietnam**

## 0. PROBLEM DEFINITION (Y)

**Current problem:** Regression + Classification

**ƒê·∫ßu ra y** = volatility trung b√¨nh trong **5 ng√†y t·ªõi**:

$$
	ext{volatility}_t = \frac{1}{5} \sum_{k=1}^{5} \sigma_{20}(r_{t+k})
$$

trong ƒë√≥:

$$
r_t = \log\left(\frac{Close_t}{Close_{t-1}}\right), \quad \sigma_{20}(r_{t}) = \text{std}(r_{t-19:t})
$$

**T√≥m t·∫Øt**: Model h·ªçc t·ª´ 25 ng√†y tr∆∞·ªõc ƒë·ªÉ d·ª± b√°o **ƒë·ªô bi·∫øn ƒë·ªông trung b√¨nh 5 ng√†y t·ªõi**.

## 1. OUTPUT Y - M·ª§C TI√äU D·ª∞ B√ÅO

### **Y l√† VOLATILITY (ƒê·ªô bi·∫øn ƒë·ªông gi√°)**

**ƒê·ªãnh nghƒ©a**:
> Volatility ƒëo m·ª©c ƒë·ªô bi·∫øn ƒë·ªông c·ªßa gi√° c·ªï phi·∫øu trong m·ªôt kho·∫£ng th·ªùi gian

**C√¥ng th·ª©c**:
```python
# Step 1: T√≠nh daily returns
returns = log(Close_today / Close_yesterday)

# Step 2: T√≠nh volatility (standard deviation)
volatility = std(returns, window=20 days)

# Step 3: Output y = mean volatility of next 5 days
y = mean(volatility[t+1:t+5])
```

**√ù nghƒ©a**:
- **Volatility CAO** ‚Üí Gi√° bi·∫øn ƒë·ªông M·∫†NH ‚Üí **R·ªßi ro CAO**
- **Volatility TH·∫§P** ‚Üí Gi√° ·ªïn ƒë·ªãnh ‚Üí **R·ªßi ro TH·∫§P**

---

## 2. OUTPUT FILE - C√ì TH·ªÇ M·ªû V√Ä XEM

### **File CSV ch·ª©a t·∫•t c·∫£ labels**:

```
data/results/exports/all_volatility_labels.csv
```

**Xem file**:
```bash
head -20 data/results/exports/all_volatility_labels.csv
```

**K·∫øt qu·∫£**:
```
Timestep,Stock_ID,Volatility,Split
0,STOCK_0,0.0189,train
0,STOCK_1,0.0197,train
0,STOCK_2,0.0151,train
0,STOCK_3,0.0189,train
0,STOCK_4,0.0202,train
0,STOCK_5,0.0205,train
0,STOCK_6,0.0223,train
0,STOCK_7,0.0230,train
0,STOCK_8,0.0211,train
0,STOCK_9,0.0228,train
```

**C·∫•u tr√∫c**:
- `Timestep`: Th·ªùi ƒëi·ªÉm (0 ‚Üí 521)
- `Stock_ID`: M√£ c·ªï phi·∫øu (STOCK_0 ‚Üí STOCK_97)
- `Volatility`: Gi√° tr·ªã volatility (OUTPUT Y) ‚≠ê
- `Split`: train/val/test

**T·ªïng s·ªë d√≤ng**:
```bash
wc -l data/results/exports/all_volatility_labels.csv
# Output: 73,207 samples (522 timesteps √ó 98 stocks + header)
```

---

## 3. V√ç D·ª§ C·ª§ TH·ªÇ - VOLATILITY VALUES

### **Xem volatility c·ªßa 10 c·ªï phi·∫øu ƒë·∫ßu ti√™n t·∫°i timestep 0**:

```bash
grep "^0," data/results/exports/all_volatility_labels.csv | head -10
```

**K·∫øt qu·∫£**:
```
Timestep  Stock    Volatility   √ù nghƒ©a
0         STOCK_0  0.0189       1.89%/ng√†y - ·ªîn ƒë·ªãnh ‚úÖ
0         STOCK_1  0.0197       1.97%/ng√†y - ·ªîn ƒë·ªãnh ‚úÖ
0         STOCK_2  0.0151       1.51%/ng√†y - R·∫•t ·ªïn ƒë·ªãnh ‚úÖ
0         STOCK_3  0.0189       1.89%/ng√†y - ·ªîn ƒë·ªãnh ‚úÖ
0         STOCK_4  0.0202       2.02%/ng√†y - Bi·∫øn ƒë·ªông v·ª´a ‚ö†Ô∏è
0         STOCK_5  0.0205       2.05%/ng√†y - Bi·∫øn ƒë·ªông v·ª´a ‚ö†Ô∏è
0         STOCK_6  0.0223       2.23%/ng√†y - Bi·∫øn ƒë·ªông cao ‚ö†Ô∏è
0         STOCK_7  0.0230       2.30%/ng√†y - Bi·∫øn ƒë·ªông cao ‚ö†Ô∏è
0         STOCK_8  0.0211       2.11%/ng√†y - Bi·∫øn ƒë·ªông v·ª´a ‚ö†Ô∏è
0         STOCK_9  0.0228       2.28%/ng√†y - Bi·∫øn ƒë·ªông cao ‚ö†Ô∏è
```

**Ph√¢n lo·∫°i Risk Level**:
**Risk Class** (d√πng trong classification):

G·ªçi $p_{33}, p_{67}$ l√† 2 ng∆∞·ª°ng ph·∫ßn v·ªã t√≠nh tr√™n **train set**.

$$
	ext{risk} =
\begin{cases}
0 & \text{if } y \le p_{33} \\
1 & \text{if } p_{33} < y \le p_{67} \\
2 & \text{if } y > p_{67}
\end{cases}
$$

> Hi·ªán t·∫°i ng∆∞·ª°ng r·ªßi ro ƒë∆∞·ª£c t√≠nh theo percentile (kh√¥ng c·ªë ƒë·ªãnh %), ƒë·ªÉ ph√π h·ª£p ph√¢n ph·ªëi d·ªØ li·ªáu.

---

## 4. OUTPUT FORMAT
data/results/exports/all_volatility_labels.csv
### **Trong timestep file (.pt)**:

```python
import torch
head -20 data/results/exports/all_volatility_labels.csv

print('=== OUTPUT Y ===')
print('Shape:', data.y.shape)  # (98, 1)
print('First 10 values:')
wc -l data/results/exports/all_volatility_labels.csv
```

**Output**:
```
Shape: torch.Size([98, 1])
grep "^0," data/results/exports/all_volatility_labels.csv | head -10
[0.0189, 0.0197, 0.0151, 0.0189, 0.0202, 0.0205, 0.0223, 0.0230, 0.0211, 0.0228]
```

**Gi·∫£i th√≠ch**:
- 98 stocks ‚Üí 98 volatility values
- M·ªói gi√° tr·ªã l√† 1 s·ªë th·ª±c (continuous)
- Range: typically 0.01 - 0.04 (1% - 4%)

---

### **Trong CSV file (d·ªÖ xem)**:

```bash
head data/results/exports/timestep_0.csv | cut -d',' -f1,201-202
```

**Output** (2 c·ªôt cu·ªëi):
```
Stock_ID,Volatility
STOCK_0,0.0189
STOCK_1,0.0197
STOCK_3,0.0189
STOCK_4,0.0202
```

---

## 5. PH√ÇN B·ªê VOLATILITY

df = pd.read_csv('data/results/exports/all_volatility_labels.csv')

```python
import pandas as pd

df = pd.read_csv('data/results/exports/all_volatility_labels.csv')

print('=== VOLATILITY STATISTICS ===')
print(df['Volatility'].describe())
```

**Output**:
```
count    73,206
mean     0.0218      (2.18% trung b√¨nh)
std      0.0065      (ƒë·ªô l·ªách chu·∫©n 0.65%)
min      0.0087      (0.87% - r·∫•t ·ªïn ƒë·ªãnh)
25%      0.0172      (1.72%)
50%      0.0208      (2.08% - median)
75%      0.0254      (2.54%)
max      0.0589      (5.89% - c·ª±c k·ª≥ bi·∫øn ƒë·ªông)
```

### **Ph√¢n lo·∫°i theo Risk Level**:

```python
# T√≠nh percentiles
p33 = df['Volatility'].quantile(0.33)  # ‚âà 0.018
p67 = df['Volatility'].quantile(0.67)  # ‚âà 0.022

# Ph√¢n lo·∫°i
df['Risk'] = df['Volatility'].apply(
    lambda x: 'Low' if x <= p33 else ('Medium' if x <= p67 else 'High')
)

print(df['Risk'].value_counts())
```

**Output**:
```
Medium    24,156 (33%)  - V·ª´a ph·∫£i
High      24,894 (34%)  - R·ªßi ro cao
```

---

head -20 data/results/exports/all_volatility_labels.csv

### **Output chia theo t·∫≠p**:
wc -l data/results/exports/all_volatility_labels.csv
```python
df = pd.read_csv('data/results/exports/all_volatility_labels.csv')
grep ",train$" data/results/exports/all_volatility_labels.csv | head -10
print('=== SPLIT BREAKDOWN ===')
print(df.groupby('Split')['Volatility'].describe())
grep ",test$" data/results/exports/all_volatility_labels.csv | head -10

**Output**:
```
         count    mean    std     min     max
Split                                        
train   35,770   0.0218  0.0065  0.0087  0.0589
val      7,644   0.0219  0.0066  0.0095  0.0543
test     7,742   0.0217  0.0064  0.0091  0.0512
```

**S·ªë l∆∞·ª£ng**:
- **Train**: 35,770 samples (365 timesteps √ó 98 stocks)
- **Val**: 7,644 samples (78 timesteps √ó 98 stocks)
- **Test**: 7,742 samples (79 timesteps √ó 98 stocks)

---

## 7. V√ç D·ª§ MAPPING INPUT ‚Üí OUTPUT

### **Timestep 0, Stock 0 (VNM)**:

**INPUT X**:
```
25 days √ó 8 features = 200 values
Day 0:  [1.005, -0.036, -0.655, ..., 21.39, -0.994]
Day 1:  [1.319,  0.040,  0.759, ..., 39.17, -0.907]
...
Day 24: [...]
```

**OUTPUT Y**:
```
Volatility = 0.0189 (1.89%/day)
```

**√ù nghƒ©a**:
> Model h·ªçc t·ª´ 25 ng√†y l·ªãch s·ª≠ (200 features) ƒë·ªÉ d·ª± ƒëo√°n m·ª©c ƒë·ªô bi·∫øn ƒë·ªông (volatility) c·ªßa VNM l√† 1.89%/ng√†y

---

## 8. FILE OUTPUT ƒê·ªÇ SHOW CHO TH·∫¶Y

### **File CSV (C√≥ th·ªÉ m·ªü Excel)**:

‚úÖ `data/results/exports/all_volatility_labels.csv`
   - **73,207 rows** (t·∫•t c·∫£ output labels)
   - Columns: Timestep, Stock_ID, Volatility, Split
   - C√≥ th·ªÉ m·ªü b·∫±ng Excel/Numbers
   - **ƒê√¢y l√† file QUAN TR·ªåNG NH·∫§T ƒë·ªÉ show OUTPUT**

‚úÖ `data/results/exports/timestep_0.csv`
   - 98 rows (stocks)
   - C·ªôt cu·ªëi c√πng = Volatility (OUTPUT)
   - 200 c·ªôt ƒë·∫ßu = Features (INPUT)

### **File Binary**:

‚ö†Ô∏è `data/processed/timestep_0.pt`
   - `data.y` shape (98, 1) = OUTPUT
   - Binary format, c·∫ßn Python

---

## 9. XEM OUTPUT DATA (Commands)

### **Xem CSV**:
```bash
# Xem 20 d√≤ng ƒë·∫ßu
head -20 data/results/exports/all_volatility_labels.csv

# ƒê·∫øm s·ªë l∆∞·ª£ng
wc -l data/results/exports/all_volatility_labels.csv

# Xem train set
grep ",train$" data/results/exports/all_volatility_labels.csv | head -10

# Xem test set
grep ",test$" data/results/exports/all_volatility_labels.csv | head -10
```

### **Xem t·ª´ .pt file**:
```python
import torch

data = torch.load('data/processed/timestep_0.pt', weights_only=False)

print('=== OUTPUT Y ===')
print('Shape:', data.y.shape)
print('Values:', data.y[:10].flatten())
print('Mean:', data.y.mean())
print('Std:', data.y.std())
```

### **Th·ªëng k√™ nhanh**:
```python
import pandas as pd

df = pd.read_csv('data/results/exports/all_volatility_labels.csv')

print('Total samples:', len(df))
print('\nSplit:')
print(df['Split'].value_counts())
print('\nVolatility stats:')
print(df['Volatility'].describe())
```

---

## CHECKLIST OUTPUT DATA

- ‚úÖ **C√≥ output labels**: all_volatility_labels.csv (73,207 samples)
- ‚úÖ **C√≥ split r√µ r√†ng**: train/val/test (70%/15%/15%)
- ‚úÖ **C√≥ th·ªÉ xem ƒë∆∞·ª£c**: CSV file m·ªü b·∫±ng Excel
- ‚úÖ **C√≥ th·ªëng k√™**: mean=0.0218, std=0.0065
- ‚úÖ **C√≥ ph√¢n lo·∫°i**: Low/Medium/High risk
- ‚úÖ **K√≠ch th∆∞·ªõc r√µ r√†ng**: 98 stocks √ó 522 timesteps = 51,156 samples

---

## T√ìM T·∫ÆT INPUT ‚Üí OUTPUT

```
INPUT (X):
  98 stocks √ó 8 features √ó 25 days = 19,600 values
  File: timestep_0.pt ‚Üí data.x (98, 8, 25)

OUTPUT (y):
  98 stocks √ó 1 volatility value = 98 values
  File: timestep_0.pt ‚Üí data.y (98, 1)

Mapping:
  X[stock_i] (200 features) ‚Üí y[stock_i] (1 volatility)
  
Example:
  VNM features (200 values) ‚Üí Volatility = 0.0189 (1.89%)
```

---

**Next**: Xem PH·∫¶N 3 (MODEL & TRAINING) trong file `MODEL_TRAINING.md`
