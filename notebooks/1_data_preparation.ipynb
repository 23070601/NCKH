{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e91ec73",
   "metadata": {},
   "source": [
    "# Data Preparation & Analysis\n",
    "\n",
    "**Objective**: Load, validate, and analyze the processed Vietnamese FDI stock data.\n",
    "\n",
    "**Data Source**: `data/processed/values.csv` (98 stocks × 773 trading days × 9 features)\n",
    "**Graph Data**: `data/processed/adj.npy` (98×98 correlation-based adjacency matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8049af",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ac91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Load processed data\n",
    "values_path = Path('../data/processed/values.csv')\n",
    "adj_path = Path('../data/processed/adj.npy')\n",
    "values = pd.read_csv(values_path, index_col=[0, 1])\n",
    "adj = np.load(adj_path)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Data quality metrics\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Structure\n",
    "print(\"\\n[STRUCTURE]\")\n",
    "print(f\"  Total records: {values.shape[0]:,}\")\n",
    "print(f\"  Features: {values.shape[1]}\")\n",
    "print(f\"  Unique stocks: {values.index.get_level_values('Symbol').nunique()}\")\n",
    "print(f\"  Trading days: {values.index.get_level_values('Date').nunique()}\")\n",
    "\n",
    "# Missing values\n",
    "print(\"\\n[DATA INTEGRITY]\")\n",
    "null_count = values.isnull().sum().sum()\n",
    "print(f\"  Missing values: {null_count}\")\n",
    "if null_count == 0:\n",
    "    print(\"  ✓ Complete dataset, no NaN values\")\n",
    "\n",
    "# Feature columns\n",
    "print(\"\\n[FEATURES]\")\n",
    "for i, col in enumerate(values.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# Date range\n",
    "dates = pd.to_datetime(values.index.get_level_values('Date'))\n",
    "print(\"\\n[DATE RANGE]\")\n",
    "print(f\"  Start: {dates.min().date()}\")\n",
    "print(f\"  End: {dates.max().date()}\")\n",
    "print(f\"  Duration: {(dates.max() - dates.min()).days} days\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471fa2c",
   "metadata": {},
   "source": [
    "## 2. Data Quality Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16662e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Example: Create sample data for FDI enterprises in Vietnam\n",
    "# In practice, you would load real data from:\n",
    "# - CSV files: pd.read_csv('path/to/data.csv')\n",
    "# - APIs: yfinance, VnEX\n",
    "# - Databases\n",
    "\n",
    "def generate_sample_stock_data(num_stocks=20, num_days=252*2):\n",
    "    \"\"\"\n",
    "    Generate sample stock price data for demonstration\n",
    "    num_stocks: number of FDI enterprises\n",
    "    num_days: number of trading days (~2 years)\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    dates = pd.date_range(end=datetime.now(), periods=num_days, freq='D')\n",
    "    stocks = [f'FDI_Stock_{i:02d}' for i in range(1, num_stocks + 1)]\n",
    "    \n",
    "    data_dict = {'Date': []}\n",
    "    \n",
    "    for stock in stocks:\n",
    "        # Generate realistic stock prices using geometric Brownian motion\n",
    "        np.random.seed(hash(stock) % 2**32)\n",
    "        prices = 100  # Initial price\n",
    "        price_series = [prices]\n",
    "        \n",
    "        for _ in range(num_days - 1):\n",
    "            # Drift and volatility parameters\n",
    "            drift = 0.0001\n",
    "            volatility = 0.02\n",
    "            \n",
    "            # Daily return\n",
    "            daily_return = np.random.normal(drift, volatility)\n",
    "            prices = prices * (1 + daily_return)\n",
    "            price_series.append(prices)\n",
    "        \n",
    "        data_dict[stock] = price_series\n",
    "    \n",
    "    data_dict['Date'] = dates\n",
    "    return pd.DataFrame(data_dict)\n",
    "\n",
    "# Generate sample data\n",
    "stock_data = generate_sample_stock_data(num_stocks=15, num_days=252*2)\n",
    "print(f\"Data shape: {stock_data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(stock_data.head())\n",
    "print(\"\\nData info:\")\n",
    "print(stock_data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7aad7",
   "metadata": {},
   "source": [
    "## 3. Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'values' not in globals():\n",
    "    values = pd.read_csv('../data/processed/values.csv', index_col=[0, 1])\n",
    "\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(\"-\" * 70)\n",
    "stats = values.describe().T\n",
    "print(stats[['mean', 'std', 'min', 'max']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399909a",
   "metadata": {},
   "source": [
    "## 4. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80506091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'values' not in globals():\n",
    "    values = pd.read_csv('../data/processed/values.csv', index_col=[0, 1])\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(values.columns):\n",
    "    axes[idx].hist(values[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'{col} Distribution')\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/analysis/feature_distributions.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Distribution plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8084e3c9",
   "metadata": {},
   "source": [
    "## 5. Stock-Wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'values' not in globals():\n",
    "    values = pd.read_csv('../data/processed/values.csv', index_col=[0, 1])\n",
    "\n",
    "# Stock-wise statistics\n",
    "stock_stats = values.groupby(level='Symbol')[['Close', 'DailyLogReturn', 'RSI']].agg(['mean', 'std', 'min', 'max'])\n",
    "print(\"\\nTop 10 Stocks by Average Price:\")\n",
    "print(values.groupby(level='Symbol')['Close'].mean().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop 10 Stocks by Daily Return Volatility:\")\n",
    "print(values.groupby(level='Symbol')['DailyLogReturn'].std().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ebe8d",
   "metadata": {},
   "source": [
    "## 6. Adjacency Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure adjacency is loaded\n",
    "if 'adj' not in globals():\n",
    "    adj = np.load('../data/processed/adj.npy')\n",
    "\n",
    "# Adjacency matrix statistics\n",
    "print(\"\\n[ADJACENCY MATRIX ANALYSIS]\")\n",
    "print(f\"Shape: {adj.shape}\")\n",
    "print(f\"Non-zero edges: {np.count_nonzero(adj)}\")\n",
    "print(f\"Density: {np.count_nonzero(adj) / (adj.shape[0] * adj.shape[1]):.6f}\")\n",
    "print(f\"Symmetric: {np.allclose(adj, adj.T)}\")\n",
    "\n",
    "# Degree distribution\n",
    "degrees = adj.sum(axis=1)\n",
    "print(f\"\\nDegree Distribution:\")\n",
    "print(f\"  Mean degree: {degrees.mean():.2f}\")\n",
    "print(f\"  Max degree: {int(degrees.max())}\")\n",
    "print(f\"  Min degree: {int(degrees.min())}\")\n",
    "\n",
    "# Visualize adjacency matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(adj, cmap='viridis', aspect='auto')\n",
    "ax.set_title('Stock Adjacency Matrix (Correlation-based)')\n",
    "ax.set_xlabel('Stock Index')\n",
    "ax.set_ylabel('Stock Index')\n",
    "plt.colorbar(im, ax=ax, label='Correlation')\n",
    "plt.savefig('../data/analysis/adjacency_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Adjacency matrix visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668b768",
   "metadata": {},
   "source": [
    "## 7. Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'values' not in globals():\n",
    "    values = pd.read_csv('../data/processed/values.csv', index_col=[0, 1])\n",
    "\n",
    "# Plot key stocks over time\n",
    "top_stocks = ['VNM', 'SAB', 'VIC', 'VHM', 'HPG']\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 12))\n",
    "\n",
    "for idx, stock in enumerate(top_stocks):\n",
    "    stock_data = values.loc[stock]\n",
    "    axes[idx].plot(pd.to_datetime(stock_data.index), stock_data['Close'], linewidth=1.5, label='Close Price')\n",
    "    axes[idx].set_title(f'{stock} - Closing Price')\n",
    "    axes[idx].set_ylabel('Price (VND)')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].legend()\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/analysis/timeseries_topstocks.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Time series visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07a52e",
   "metadata": {},
   "source": [
    "## 8. Data Export for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e620b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrices for analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'values' not in globals():\n",
    "    values = pd.read_csv('../data/processed/values.csv', index_col=[0, 1])\n",
    "\n",
    "output_dir = '../data/features'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Unstack to create stock × date matrix for each feature\n",
    "for feature in ['Close', 'DailyLogReturn', 'RSI', 'MACD']:\n",
    "    feature_matrix = values[feature].unstack(level='Symbol')\n",
    "    output_file = f'{output_dir}/{feature.lower()}_matrix.csv'\n",
    "    feature_matrix.to_csv(output_file)\n",
    "    print(f\"✓ Saved {feature} matrix: {feature_matrix.shape}\")\n",
    "\n",
    "# Save ticker list\n",
    "ticker_list = values.index.get_level_values('Symbol').unique()\n",
    "ticker_df = pd.DataFrame({'ticker': ticker_list})\n",
    "ticker_df.to_csv(f'{output_dir}/tickers.csv', index=False)\n",
    "print(f\"\\n✓ Saved {len(ticker_list)} tickers to features/tickers.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Data preparation complete! Ready for analysis.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
